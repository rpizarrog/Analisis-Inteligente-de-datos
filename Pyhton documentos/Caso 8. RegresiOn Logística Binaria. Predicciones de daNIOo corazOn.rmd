---
title: "Caso 8. Regresi√≥n Log√≠stica Binaria. Predicciones de da√±o coraz√≥n. Lenguaje R"
author: "Rub√©n Pizarro Gurrola"
date: "`r Sys.Date()`"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
    toc_depth: 6
    number_sections: yes
bibliograph: references.bib
bibliography: references.bib
---

# Objetivo

Implementar el modelo de regresi√≥n log√≠stica binaria con datos relacionados a una condici√≥n de salud de las personas para predecir anomal√≠as de coraz√≥n y evaluar la exactitud del modelo mediante la matriz de confusi√≥n.

# Descripci√≥n

Se cargan librer√≠as y se descargan los datos: <https://raw.githubusercontent.com/rpizarrog/Analisis-Inteligente-de-datos/main/datos/heart_2020_cleaned.csv>

Los datos est√°n relacionados con aspectos m√©dicos y son valores num√©ricos de varias variables que caracterizan el estado de salud de 319,795 personas.

Se pretende construir un modelo utilizando **algoritmos supervisados** para resolver la **tarea de clasificaci√≥n binaria** e identificar si una persona padece del coraz√≥n o no.

Se construyen datos de entrenamiento y validaci√≥n al 80% y 20% cada uno.

Se desarrollan los modelos de:

-   **Regresi√≥n Log√≠stica binaria**

-   √Årbol de Clasificaci√≥n tipo class

-   K Means

-   SVM Lineal

-   SVM Polinomial

-   SVM Radial

Los modelo se aceptan si tienen un valor de exactitud ("*Accuracy*") por encima del 70%..

# Fundamento te√≥rico

La regresi√≥n log√≠stica ofrece soluci√≥n para clasificar y para predecir valores l√≥gicos, es decir con un valor etiquetado tal vez 0 o 1; bueno o malo, alto o bajo, entre otras etiquetas que distingan una polaridad o significado dicot√≥mico, o un valor u otro.

Para predicciones el modelo de regresi√≥n log√≠stica binaria encuentra la probabilidad de ocurrencia de un evento determinado y dicha probabilidad se hallar√° siempre dentro del rango.

Cuando la variable respuesta posee dos categor√≠as, entonces se estar√° delante de una regresi√≥n log√≠stica binaria.

En cambio, si la variable respuesta posee m√°s de dos categor√≠as, se usar√° la regresi√≥n log√≠stica multinomial [@zang2020]

En este caso que se presenta y describe a continuaci√≥n, se utiliza la regresi√≥n log√≠stica binomial como parte de los algoritmos supervisados de *machine learning*.

El modelo requiere una cantidad de variables independientes del modelo $x_1, x_2 ... x_n$ √≥ $\beta_1, \beta_2...\beta_n$.

Se debe identificar la variable dependiente $Y$ o la variable respuesta de tipo binaria, donde cada componente de ùëå se distribuye mediante una distribuci√≥n de Bernoulli $[ 0 | 1]$.

Se necesitan $ùëõ$ el n√∫mero de observaciones.

Entonces $ùëã = (ùë•_1, ‚Ä¶ , ùë•_ùëõ)^T$ el conjunto de variable independientes.

Se identifica como $\theta$ el vector de par√°metros asociado al modelo, de forma que $\theta\in R^{k+1}$ que significa que los valores del vector resultante pertenecen a cada una de las variables.

Sea $\pi(\theta^Tùë•_ùëñ)$ la probabilidad de que $Y_i$ tome un valor igual a $1$, entonces su modelo se puede escribir como:$$
\pi(\theta^Tx_i) = P(Y =1|X=x) = \frac{1}{1+e}
$$

Si $\theta^Tx_i$ los valores ajustados toma valores elevados y positivos, entonces ... ... se aproximar√° a 0 y, en consecuencia, el valor de la funci√≥n anterior ser√° igual a 1. En caso de que $\theta^Tx_i$ tome valores elevados pero negativos, entonces el valor de la funci√≥n ser√° $0$ dado que $e ^ {\theta^Tx_i}$ tender√° a infinito. [@zang2020].

El valor $e$ como n√∫mero irracional y basado en la teor√≠a de logaritmos naturales es el valor constante que se puede obtener en lenguaje R con la funci√≥n *exp(1)* igual a `r exp(1)`.

Efectuando la transformaci√≥n logit a la expresi√≥n inicial, se obtiene:

$$
logit(\pi(\theta^Tx_i)) = ln(\frac{\pi(\theta^Tx_i)}{1 - \pi(\theta^Tx_i)})
$$

que significa calcular el logaritmo natural de cada valor de de $x_i$ para determinar su probabilidad.

# Desarrollo

## Cargar librer√≠as

```{r message=FALSE, warning=FALSE}
library(readr)
library(dplyr)
library(caret)
library(rpart)
library(rpart.plot)
library(knitr)
library(e1071)        # Vectores de Soporte SVM
library(rpart)        # Arboles de clasificaci√≥n
```

## Cargar datos

Cargar datos de manera local por la tardanza de hacerlo desde la ruta de github. Lo recomendable es descargar los datos en ruta local.

```{r}
# datos <- read.csv("https://raw.githubusercontent.com/rpizarrog/Analisis-Inteligente-de-datos/main/datos/heart_2020_cleaned.csv")
datos <- read.csv("../../datos/heart_2020_cleaned.csv", encoding = "UTF-8", stringsAsFactors = TRUE)
```

## Explorar datos

Son 319795 observaciones y 17 variables

```{r}
str(datos)
summary(datos)
```

## Transformar datos

Crear variable llamada *HeartDisease01* que se utilizar√° en el modelo de **Regresi√≥n Log√≠stica** tendr√° valores **0** de para no da√±o y **1** para da√±o del coraz√≥n.

```{r}
datos = mutate (datos,HeartDisease_01=if_else(HeartDisease=='Yes',1,0))
```

## Las variables de inter√©s

Todas las variables de entrada o variables independientes:

-   "*BMI*": Indice de masa corporal con valores entre 12.02 y 94.85.

-   "*Smoking*": Si la persona es fumadora o no con valores categ√≥ritos de 'Yes' o 'No'.

-   "*AlcoholDrinking*" : Si consume alcohol o no, con valores categ√≥ricos de 'Yes' o 'No'.

-   "*Stroke*": Si padece alguna anomal√≠a cerebrovascular, apoplejia o algo similar, con valores categ√≥ricos de 'Yes' o 'No'.

-   "*PhysicalHealth*" Estado f√≠sico en lo general con valores entre 0 y 30.

-   "*MentalHealth*". Estado mental en lo general con valores entre 0 y 30.

-   "*DiffWalking*" . Que si se le dificulta caminar o tiene alg√∫n padecimiento al caminar, con valores categ√≥ritoc de 'Yes' o 'No'.

-   "*Sex*": G√©nero de la persona, con valores de 'Female' y 'Male' para distinguir al g√©nero femenino y masculino respectivamente.

-   "*AgeCategory*": Una clasificaci√≥n de la edad de la persona de entre 18 y 80 a√±os. La primera categor√≠a con un rango de edad entre 18-24, a partir de 25 con rangos de 5 en 5 hasta la clase de 75-80 y una √∫ltima categor√≠a mayores de 80 a√±os.

-   "*Race*". Raza u origen de la persona con valores categ√≥ricos de '*American Indian/Alaskan Native', 'Asian','Black', 'Hispanic', 'Other'* y'*White'.*

-   "*Diabetic*". Si padece o ha padecido de diabetes en cuatro condiciones siendo Yes y No para si o no: 'No', 'borderline diabetes' condici√≥n antes de detectarse diabetes tipo 2, 'Yes', y 'Yes (during pregnancy)' durante embarazo.

-   "*PhysicalActivity*" que si realiza actividad f√≠sica, con valores categ√≥ricos de 'Yes' o 'No'.

-   "*GenHealth*": EStado general de salud de la persona con valores categ√≥ricos de 'Excellent', 'Very good', 'Good', 'Fair' y 'Poor' con significado en espa√±ol de excelente, muy buena, buena, regular y pobre o deficiente.

-   "*SleepTime*": valor num√©rico de las horas de sue√±o u horas que duerme la persona con valores en un rango entre 1 y 24.

-   "*Asthma*": si padece de asma o no, con valores categ√≥ricos de 'Yes' o 'No'.

-   "*KidneyDisease*": si tiene alg√∫n padecimiento en los ri√±ones, con valores categ√≥ricos de 'Yes' o 'No'.

-   "*SkinCancer*": si padece alg√∫n tipo de c√°ncer de piel, con valores categ√≥ricos de 'Yes' o 'No'.

La variable de inter√©s como dependiente o variable de salida es la de da√±o al coraz√≥n (*HeartDisease*), con valores categ√≥ricos de 'Yes' o 'No'.

## Datos de entrenamiento y validaci√≥n

Se parten los datos en en datos de entrenamiento con el 80% y datos de validaci√≥n con el 20%.

```{r}
set.seed(2022)
entrena <- createDataPartition(y = datos$HeartDisease, 
                               p = 0.8, 
                               list = FALSE, 
                               times = 1)
# Datos entrenamiento
datos.entrenamiento <- datos[entrena, ]  # [renglones, columna]
# Datos validaci√≥n
datos.validacion <- datos[-entrena, ]
```

### Datos de entrenamiento

Se muestran los primeros 20 registros datos de entrenamiento

```{r}
kable(head(datos.entrenamiento, 20), caption = "Primeros 20 registros de datos de entrenamiento")
```

### Datos de validaci√≥n

Se muestran los primeros 20 registros de datos de validaci√≥n .

```{r}
kable(head(datos.entrenamiento, 20), caption = "Primeros 20 registros de datos de entrenamiento")
```

## Regresi√≥n Log√≠stica binomial

Se construye el modelo con los datos de entrenamiento mediante la funci√≥n *glm()* indicando que es regresi√≥n log√≠stica binomial es decir solo dos valores.

```{r}
modelo.rl = glm(data = datos.entrenamiento,formula =    HeartDisease_01 ~ BMI+Smoking+AlcoholDrinking+Stroke+PhysicalHealth+MentalHealth+DiffWalking+Sex
+AgeCategory+Race+Diabetic+PhysicalActivity+GenHealth+SleepTime+Asthma+KidneyDisease+SkinCancer, family = binomial())
```

### Resumen y/o estad√≠sticos del modelo

El resumen del modelo muestra algunos estad√≠sticos importantes: se interpreta que la gran mayor√≠a de las variables independiente tienen significaci√≥n estad√≠stica '\*\*\*', presenta los coeficientes num√©ricos en la ecuaci√≥n de regresi√≥n log√≠stica entre otras cosas.

```{r}
summary(modelo.rl)
```

Entonces una posible predicci√≥n ser√≠a de la siguiente manera:

$$
Y=Œ≤_0+Œ≤_1‚ãÖ(coeficiente)+Œ≤_2‚ãÖ(coeficiente)+Œ≤_3‚ãÖ(coeficiente)+...+Œ≤_n‚ãÖ(coeficiente
$$

entonces ...

$$
HeartDisease\text{01} = -6.3411940 +BMI‚ãÖ(coeficiente) +SmokingYes\cdot(coeficiente) + ... + SkinCancerYes\cdot(coeficiente) 
$$

### Generar predicciones del modelo regresi√≥n log√≠stica

Se generan predicciones con datos de validaci√≥n generando un valor num√©rico que deber√° convertirse a valor probabil√≠stico, condicionando que si el valor de la probabilidad de predicci√≥n est√° por debajo del 50% es 0 y si est√° por encima entonces ser√° 1.

```{r}
prediciones_rl = predict(object = modelo.rl,newdata = datos.validacion, se.fit = TRUE)
```

### Probabilidad con la funci√≥n logit

Se transforman los valores de las predicciones generadas a valores probabil√≠sticos usando para ello el concepto de la funci√≥n logit. $$
prob = \frac{exp(prediccion)}{(1 + exp(prediccion))}
$$

```{r}
prediciones_rl_prob <- exp(prediciones_rl$fit) / (1 + exp(prediciones_rl$fit))
```

### Generar tabla comparativa

Se construye una tabla comparativa con los valores de inter√©s

```{r}
t_comparativa = data.frame(datos.validacion[,c('HeartDisease', 'HeartDisease_01')],prediciones_rl_prob)
t_comparativa <- t_comparativa %>%
  mutate(heartDiseasePred = if_else(prediciones_rl_prob < 0.50, 0, 1))
top20 = head(t_comparativa,20)
kable(top20,caption = 'Primeros 20 registros')
```

### Evaluando el modelo

Una matriz de confusi√≥n es una herramienta que permite evaluaci√≥n de un modelo de clasificaci√≥n

Cada columna de la matriz representa el n√∫mero de predicciones de cada clase, mientras que cada fila representa a las instancias en la clase real.

Uno de los beneficios de las matrices de confusi√≥n es que facilitan ver si el sistema est√° confundiendo las diferentes clases o resultados.

Hay que encontrar a cuantos casos se le atinaron utilizando los datos de validaci√≥n y con ello encontrar el porcentaje de aciertos.

![](images/matriz%20de%20confusion.jpg){width="500"}

Se puede evaluar el modelo con la matriz de confusi√≥n interpretando algunos estad√≠sticos:

Se eval√∫a el modelo de acuerdo a estas condiciones:

-   Accuracy o exactitud $$
    accuracy = \frac{VP + FP}{n}
    $$

-   Precision o precisi√≥n

$$
precision = \frac{TP}{VP + FP}
$$

-   Recall o recuperaci√≥n $$
    recall = \frac{VP}{VP + FN}
    $$

-   Especificity o especificidad (tasa de verdaderos negativos)

$$
especificity = \frac{VP}{VN + FP}
$$

#### Construyendo la matriz de confusi√≥n del modelo de regresi√≥n log√≠stica

Factorizar las columnas "*HeartDisease_01*" & "heartDiseasePred" de la tabla comparativa

Factorizar en R significa categorizar con la funci√≥n "*as.factor()*" o "factor"

Se muestra a tabla con las columnas de inter√©s para interpretar las predicciones.

```{r}
t_comparativa$HeartDisease_01 = as.factor(t_comparativa$HeartDisease_01)
t_comparativa$heartDiseasePred = as.factor(t_comparativa$heartDiseasePred)
kable(head(t_comparativa, 20), caption = "Tabla comparativa, primeros 20 registros")
```

Creando de la matriz de confusi√≥n con la funci√≥n *confusionMatrix()* de la librer√≠a caret con las variables de inter√©s: **"*HeartDisease_01*"** y **"*heartDiseasePred*",** que representan los valores reales y las predicciones respectivamente.

```{r}
matrixConfusion <- confusionMatrix(t_comparativa$HeartDisease_01,t_comparativa$heartDiseasePred)
matrixConfusion
```

El valor estad√≠stico de *Accuracy* = Exactitud igual a 0.9153 significa un valor del 91.53%; se interpreta que de cada 100 el modelo acierta en la predicci√≥n el 91.53% de las ocasiones.

Si la m√©trica era que debiera tener un valor por encima del 70% el modelo se acepta pero debe compararse contra otro modelo de clasificaci√≥n para ver cual es m√°s eficiente en relaci√≥n tan solo en el estad√≠stico de Exactitud.

Este valor de *Accuracy* = Exactitud deber√° compararse contra otros modelos.

## Predicciones con datos nuevos

Se crea un registro de una persona con ciertas condiciones de salud.

```{r}
BMI <- 38
Smoking <- 'Yes'
AlcoholDrinking = 'Yes'
Stroke <- 'Yes'
PhysicalHealth <- 2
MentalHealth = 5
DiffWalking = 'Yes'
Sex = 'Male'
AgeCategory = '70-74'
Race = 'Black'
Diabetic <- 'Yes'
PhysicalActivity = "No"
GenHealth = "Fair"
SleepTime = 12
Asthma = "Yes"
KidneyDisease = "Yes"
SkinCancer = 'No'
persona <- data.frame(BMI,Smoking, AlcoholDrinking, Stroke, PhysicalHealth, MentalHealth, DiffWalking, Sex, AgeCategory, Race, Diabetic, PhysicalActivity, GenHealth, SleepTime, Asthma, KidneyDisease, SkinCancer)
persona
```

Se hace la predicci√≥n con estos valores de si tiene p no da√±o en el coraz√≥n:

```{r}
prediccion <- predict(object = modelo.rl, newdata = persona, se.fit = TRUE)
prediccion
# prediccion <- prediccion$fit
# prediccion
```

Este valor 0.06995949 a valor probabil√≠stico:

```{r}
prob <- exp(prediccion$fit) / (1 + exp(prediccion$fit))
prob
```

Tiene un valor de 0.7480466 es decir un 74.80%

Entonces en predicci√≥n es:

```{r}
pred <- if_else (prob > 0.5, 1, 0)
pred
```

Si la predicci√≥n es es 0 no tienen afecci√≥n del coraz√≥n en caso se contrario si el resultado es 1 entonces la predicci√≥n implica que si tiene da√±o del coraz√≥n.

# Interpretaci√≥n

Pendiente ...

# Bibliograf√≠a
