---
title: "Caso 10. Vecinos mas cercanos KNN. Clasificación Daños al Corazón en R"
author: "Rubén Pizarro Gurrola"
date: "`r Sys.Date()`"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
    toc_depth: 6
    number_sections: yes
bibliography: references.bib
---

# Objetivo

Implementar el modelo de vecinos mas cercanos KNN co programamción R para reolver la tarea de clasificación de una condición de salud de las personas mediante predicción de anomalías de corazón evalundo la exactitud del modelo mediante la matriz de confusión.

# Descripción

Se cargan librerías y se descargan los datos: <https://raw.githubusercontent.com/rpizarrog/Analisis-Inteligente-de-datos/main/datos/heart_2020_cleaned.csv>

Los datos están relacionados con aspectos médicos y son valores numéricos de varias variables que caracterizan el estado de salud de 319,795 personas.

Se construye un modelo supervisado basado en el algoritmo de vecinos mas cercanos KNN para resolver la tarea de clasificación binaria e identificar si una persona padece del corazón o no.

Primero se construye un modelo KNN con la función use la función *train.kknn()* de la librería *kknn*

Luego se construye un similar modelo pero con la función *knn()* de la librería *class*.

Se construyen datos de entrenamiento y validación al 80% y 20% cada uno.

Se desarrollan los modelos de:

-   Regresión Logística binaria

-   Árbol de Clasificación tipo class

-   **KNN Vecinos mas cercanos**

-   SVM Lineal

-   SVM Polinomial

-   SVM Radial

Los modelo se aceptan si tienen un valor de exactitud por encima del 70%..

# Fundamento teórico

El algoritmo vecinos mas cercanos KNN clasifica cada dato nuevo en el grupo que corresponda, según tenga *k* vecinos más cerca de un grupo o de otro. Es decir, calcula la distancia del elemento nuevo a cada uno de los existentes, y ordena dichas distancias de menor a mayor para ir seleccionando el grupo al que pertenecer.

Este grupo será, por tanto, el de mayor frecuencia con menores distancias.

El KNN es un algoritmo de **aprendizaje supervisado**, es decir, que a partir de un juego de datos inicial su objetivo será el de clasificar correctamente todas las instancias nuevas. El juego de datos típico de este tipo de algoritmos está formado por varios atributos descriptivos y un solo atributo objetivo (también llamado clase).

El método **K-NN** es un método importantes de clasificación supervisada. En el proceso de aprendizaje no se hace ninguna suposición acerca de la distribución de las variables predictoras, es por ello que es un método de clasificación no paramétrico, que estima el valor de la función de densidad de probabilidad o directamente la probabilidad posterior de que un elemento xx pertenezca a la clase CjCj a partir de la información proporcionada por el conjunto de entrenamiento.

Es un método bastante sencillo y robusto que simplemente busca en las observaciones más cercanas a la que se está tratando de predecir y clasifica el punto de interés basado en la mayoría de datos que le rodean.

Es un algoritmo muy simple de implementar y de entrenar, pero tienen una carga computacional elevada y **no es apropiado cuando se tienen muchos grados de libertad.**

# Desarrollo

## Cargar librerías

```{r message=FALSE, warning=FALSE}
library(readr) # Leer datos
library(kknn)  # KNN modelo para kknn
library(dplyr) # Procesar filtrar
library(forcats)   # para decodificar vars
library(class)     # Para knn()
library(caret)     # Matriz de confusión entre otros
library(reshape)   # Para modificar variables 
library(knitr)     # Para tablas amigables
```

## Cargar datos

Cargar datos de manera local.

```{r}
datos <- read.csv("https://raw.githubusercontent.com/rpizarrog/Machine-Learning-con-R/main/datos/heart_2020_cleaned.csv", stringsAsFactors = TRUE, encoding = "UTF-8")
# datos <- read.csv("../../datos/heart_2020_cleaned.csv", encoding = "UTF-8", stringsAsFactors = TRUE)
```

## Explorar datos

Son 319795 registros y 18 observaciones. El 80% serán datos de entrenamiento y el 20% serán datos de validación.

La variable *HeartDisease* es de tipo factor y tiene dos niveles *"No" y "Yes".*

```{r}
str(datos)
summary(datos)
```

## Limpiar datos

No es necesario alguna transformación

## Las variables de interés

Todas las variables son de entrada o variables independientes:

-   "*BMI*": Indice de masa corporal con valores entre 12.02 y 94.85.

-   "*Smoking*": Si la persona es fumadora o no con valores categóritos de 'Yes' o 'No'.

-   "*AlcoholDrinking*" : Si consume alcohol o no, con valores categóricos de 'Yes' o 'No'.

-   "*Stroke*": Si padece alguna anomalía cerebrovascular, apoplejia o algo similar, con valores categóricos de 'Yes' o 'No'.

-   "*PhysicalHealth*" Estado físico en lo general con valores entre 0 y 30.

-   "*MentalHealth*". Estado mental en lo general con valores entre 0 y 30.

-   "*DiffWalking*" . Que si se le dificulta caminar o tiene algún padecimiento al caminar, con valores categóritoc de 'Yes' o 'No'.

-   "*Sex*": Género de la persona, con valores de 'Female' y 'Male' para distinguir al género femenino y masculino respectivamente.

-   "*AgeCategory*": Una clasificación de la edad de la persona de entre 18 y 80 años. La primera categoría con un rango de edad entre 18-24, a partir de 25 con rangos de 5 en 5 hasta la clase de 75-80 y una última categoría mayores de 80 años.

-   "*Race*". Raza u origen de la persona con valores categóricos de '*American Indian/Alaskan Native', 'Asian','Black', 'Hispanic', 'Other'* y'*White'.*

-   "*Diabetic*". Si padece o ha padecido de diabetes en cuatro condiciones siendo Yes y No para si o no: 'No', '*borderline* diabetes' condición antes de detectarse diabetes tipo 2, 'Yes', y 'Yes (*during* *pregnancy*)' durante embarazo.

-   "*PhysicalActivity*" que si realiza actividad física, con valores categóricos de 'Yes' o 'No'.

-   "*GenHealth*": EStado general de salud de la persona con valores categóricos de '*Excellent*', '*Very good', 'Good', 'Fair' y 'Poor*' con significado en español de excelente, muy buena, buena, regular y pobre o deficiente.

-   "*SleepTime*": valor numérico de las horas de sueño u horas que duerme la persona con valores en un rango entre 1 y 24.

-   "*Asthma*": si padece de asma o no, con valores categóricos de 'Yes' o 'No'.

-   "*KidneyDisease*": si tiene algún padecimiento en los riñones, con valores categóricos de 'Yes' o 'No'.

-   "*SkinCancer*": si padece algún tipo de cáncer de piel, con valores categóricos de 'Yes' o 'No'.

La variable de interés como dependiente o variable de salida es la de daño al corazón (HeartDisease), con valores categóricos de 'Yes' o 'No'.

## Datos de entrenamiento y validación

Se parten los datos en en datos de entrenamiento con el 80% y datos de validación con el 20%.

```{r}
set.seed(2022)
entrena <- createDataPartition(y = datos$HeartDisease, 
                               p = 0.8, 
                               list = FALSE, 
                               times = 1)
# Datos entrenamiento
datos.entrenamiento <- datos[entrena, ]  # [renglones, columna]
# Datos validación
datos.validacion <- datos[-entrena, ]
```

### Datos de entrenamiento

Se muestran los primeros 20 registros datos de entrenamiento

```{r}
kable(head(datos.entrenamiento, 20), caption = "Primeros 20 registros de datos de entrenamiento")
```

### Datos de validación

Se muestran los primeros 20 registros de datos de validación .

```{r}
kable(head(datos.validacion, 20), caption = "Primeros 20 registros de datos de validación")
```

## Modelo de clasificación 1. Vecinos mas cercanos KNN

Se crea el modelo de vecinos mas cercanos con la función *train.kknn().*

Se construye una muestra de 10000 (diezmil) registros a partir de los datos de entrenamiento con lo cual precisamente se construye el modelo KNN, Esto se hace aquí en R, dado que la limitante es la gran cantidad de observaciones como desventaja del modelo., El modelo sería para pequeños conjunto de datos.

```{r}
muestra <- sample(x = 1:nrow(datos.entrenamiento), size = 10000, replace = FALSE)
```

```{r}
modelo.knnn <- train.kknn(data = datos.entrenamiento[muestra, ], formula = HeartDisease ~ ., ks = 12, kmax = 30)
```

### Predicciones del modelo

Se hacen predicciones con los datos de validación usando el modelo que se construyó. en la variable *modelo.knnn.*

```{r}
predicciones <- predict(object = modelo.knnn, newdata = datos.validacion)
```

### Evaluación del modelo

Construir matriz par comparar las predicciones con los valores reales de los datos de validación de la variable *HeartDisease* contrastada con las predicciones.

```{r}
datos.comparar <- data.frame("real" = datos.validacion$HeartDisease, "predicho" = predicciones)

kable(head(datos.comparar, 20), caption = "Datos a comparar previo a matriz de confusión" )
```

#### Matriz de confusión

```{r}
matriz <- confusionMatrix(datos.comparar$real, datos.comparar$predicho)

matriz
```

Se tiene un valor de *accuracy* = exactitud de 0.9053 o de \$90.53%\$ que significa que el modelo le atina en la predicción o clasificación aproximadamente al 90% de cada 100 casos procesados.

### Predecir un caso nuevo

Se crea un registro de una persona con ciertas condiciones de salud.

```{r}
BMI <- 38
Smoking <- 'Yes'
AlcoholDrinking = 'Yes'
Stroke <- 'Yes'
PhysicalHealth <- 2
MentalHealth = 5
DiffWalking = 'Yes'
Sex = 'Male'
AgeCategory = '70-74'
Race = 'Black'
Diabetic <- 'Yes'
PhysicalActivity = "No"
GenHealth = "Fair"
SleepTime = 12
Asthma = "Yes"
KidneyDisease = "Yes"
SkinCancer = 'No'
persona <- data.frame(BMI,Smoking, AlcoholDrinking, Stroke, PhysicalHealth, MentalHealth, DiffWalking, Sex, AgeCategory, Race, Diabetic, PhysicalActivity, GenHealth, SleepTime, Asthma, KidneyDisease, SkinCancer)
persona
```

Convertir a factores las variables tipo *char* par que el modelo entienda que precisamente son de tipo actor y tienen sus niveles. Se convierte al mismo tipo que los datos de validación para cada variable de tipo *char* de la persona.

```{r}

persona$Smoking <- factor(persona$Smoking, levels = levels(datos.validacion$Smoking))

persona$AlcoholDrinking <- factor(persona$AlcoholDrinking, levels = levels(datos.validacion$AlcoholDrinking))

persona$Stroke <- factor(persona$Stroke, levels = levels(datos.validacion$Stroke))

persona$DiffWalking <- factor(persona$DiffWalking, levels = levels(datos.validacion$DiffWalking))

persona$Sex <- factor(persona$Sex, levels = levels(datos.validacion$Sex))

persona$AgeCategory <- factor(persona$AgeCategory, levels = levels(datos.validacion$AgeCategory))

persona$Race <- factor(persona$Race, levels = levels(datos.validacion$Race))

persona$Diabetic <- factor(persona$Diabetic, levels = levels(datos.validacion$Diabetic))

persona$PhysicalActivity <- factor(persona$PhysicalActivity, levels = levels(datos.validacion$PhysicalActivity))


persona$GenHealth <- factor(persona$GenHealth, levels = levels(datos.validacion$GenHealth))


persona$Asthma <- factor(persona$Asthma, levels = levels(datos.validacion$Asthma))

persona$KidneyDisease <- factor(persona$KidneyDisease, levels = levels(datos.validacion$KidneyDisease))

persona$SkinCancer <- factor(persona$SkinCancer, levels = levels(datos.validacion$SkinCancer))


```

Se hace la predicción con estos valores:

Primero con el modelo de clasificación 1 *modelo.knnn*:

```{r}
prediccion <- predict(object = modelo.knnn, newdata = persona)
prediccion

```

La predicción es que **LA PERSONA SI** se clasifica con daño al corazón con el modelo *modelo.knnn.*

## Modelo de clasificación 2. Vecinos mas cercanos KNN

Se construye un segundo modelo. Ahora, se hace la construcción del modelo usando otra función pero que también tiene que ver con el algoritmo de vecinos mas cercanos. Se usa la función *knn()* de la librería *class.*

Se reconstruyen los mismos datos de entrenamiento y validación, sin embargo, se hace una limpieza de las variables que son categóricas transformadas a valores numéricos.

Esto se hace dado que la librería *class* y la función *knn()* así lo pide.

### Preparar los datos

El proceso de limpieza es transformar variables

Se construye un *data.frame* similar pero llamado *datos2* con variables numéricas en lugar de factores; esto se hace para el modelo se construya con la función *knn()*.

Primero se transforman las variables dicotómicas que serían: *Smoking, AlcoholDrinking, Stroke, DiffWalking, Sex PhysicalActivity, Asthma, KidneyDisease, SkinCancer*

```{r}
datos2 <- datos %>%
  mutate(Smoking = if_else(Smoking == 'Yes', 1, 2), AlcoholDrinking = if_else(AlcoholDrinking == 'Yes', 1, 2), Stroke = if_else(Stroke == 'Yes', 1, 2), DiffWalking = if_else(DiffWalking == 'Yes', 1, 2), Sex = if_else(Sex == 'Female', 1, 2), PhysicalActivity = if_else(PhysicalActivity == 'Yes', 1, 2), Asthma = if_else(Asthma == 'Yes', 1, 2), KidneyDisease = if_else(KidneyDisease == 'Yes', 1, 2), SkinCancer = if_else(SkinCancer == 'Yes', 1, 2))
```

Luego la variable *AgeCategory* que transforma las categóricas de edades a variable numéricas pero en jerarquía o nveles del 1 al 12, un nivel para cada categoría de edad.

```{r}
datos2 <- datos2 %>%
  mutate(AgeCategory = ifelse (AgeCategory == '18-24',  1, ifelse(AgeCategory == '25-29', 2, ifelse(AgeCategory == '30-34', 3, ifelse(AgeCategory == '35-39', 4, ifelse(AgeCategory == '40-44', 5, ifelse(AgeCategory == '45-49', 6, ifelse(AgeCategory == '50-54', 7, ifelse(AgeCategory == '55-59', 8, ifelse(AgeCategory == '60-64', 9, ifelse(AgeCategory == '65-69', 10, ifelse(AgeCategory == '70-74', 11, ifelse(AgeCategory == '75-79', 12, 13))))))))))))) 
```

Luego la variable *Race* secategoriza con valores numéricos del 1 al 6, uno por cada raza.

```{r}
datos2 <- datos2 %>%
  mutate(Race = ifelse (Race == 'White',  1, ifelse(Race == 'Black', 2, ifelse(Race == 'Asian', 3, ifelse(Race == 'American Indian/Alaskan Native', 4, ifelse(Race == 'Other', 5, 6 )))))) 
```

La variable *Diabetic* se categoriza con niveles del 1 al 4

```{r}
datos2 <- datos2 %>%
  mutate(Diabetic = ifelse (Diabetic == 'Yes',  1, ifelse(Diabetic == 'No', 2, ifelse(Diabetic == 'No, borderline diabetes', 3, 4)))) 
```

La variable *GenHealth* se transforma a valores entre 1 y 5

```{r}
datos2 <- datos2 %>%
  mutate(GenHealth = ifelse (Race == 'Fair',  1, ifelse(GenHealth == 'Poor', 2, ifelse(GenHealth == 'Good', 3, ifelse(GenHealth == 'Very good', 4, 5 )))))
```

### Datos de entrenamiento y validación

Se construyen los datos de entrenamiento y validación pero a partir de *datos2*

```{r}
set.seed(2022)
entrena <- createDataPartition(y = datos2$HeartDisease, 
                               p = 0.8, 
                               list = FALSE, 
                               times = 1)

# Datos entrenamiento
datos.entrenamiento <- datos2[entrena, ]  # [renglones, columna]

# Datos validación
datos.validacion <- datos2[-entrena, ]
```

### **Construir el modelo knn**

Nuevamente una muestra de 10000 (diezmil) registros de los datos de entrenamiento.

```{r}
muestra <- sample(x = 1:nrow(datos.entrenamiento), size = 10000, replace = FALSE)
```

El modelo automáticamente se construye con los datos de entrenamiento y datos de validación indicando en los parámetros *train* y *test* respectivamente sin incluir la primera columna [, -1] o sea *HeartDisease* que es la variable dependiente u objetivo. Luego con el parámetro *cl* se le indica la variable factor o de clasificación que este caso es *HeartDeisease* o la primer columna *[, 1], el parámetro k= 12 e* el número de vecinos a considerar que puede cambiar a discreción del científico de datos.

```{r}
predicciones.2 <- knn(train = datos.entrenamiento[muestra, -1], test = datos.validacion[, -1], cl = datos.entrenamiento[muestra,1], k = 12)
```

### Evaluación del modelo

Habiendo construido y entrenado el modelo se hace una matriz de comparación al igual que en el primer modelo *knn* de este caso que servirá para construir la matriz de confusión.

Construir matriz par comparar las predicciones con los valores reales de los datos de validación de la variable *HeartDisease* contrastada con las predicciones.

```{r}
datos.comparar <- data.frame("real" = datos.validacion$HeartDisease, "predicho" = predicciones.2)

kable(head(datos.comparar, 20), caption = "Datos a comparar previo a matriz de confusión" )
```

#### Matriz de confusión

```{r}
matriz <- confusionMatrix(datos.comparar$real, datos.comparar$predicho)

matriz
```

Se tiene un valor de *accuracy* = exactitud de 0.9137 o de $91.37\%$ que significa que el modelo le atina en la predicción o clasificación aproximadamente al 91% de cada 100 casos procesados.

### Predecir un caso nuevo

Se crea un registro de una persona con ciertas condiciones de salud.

```{r}
HeartDisease = 'No'
BMI <- 38
Smoking <- 1  # 'Yes'
AlcoholDrinking = 1 # 'Yes'
Stroke <- 1 # 'Yes'
PhysicalHealth <- 2 
MentalHealth <- 5
DiffWalking <- 1 # 'Yes'
Sex = 2 # 'Male
AgeCategory = 11 # '70-74'
Race = 2 # 'Black'
Diabetic <- 1 # 'Yes'
PhysicalActivity = 2 # 'No'
GenHealth = 1 # "Fair"
SleepTime = 12
Asthma = 1 # 'Yes'
KidneyDisease = 1 # 'Yes'
SkinCancer = 2 # 'No'

persona2 <- data.frame(HeartDisease, BMI,Smoking, AlcoholDrinking, Stroke, PhysicalHealth, MentalHealth, DiffWalking, Sex, AgeCategory, Race, Diabetic, PhysicalActivity, GenHealth, SleepTime, Asthma, KidneyDisease, SkinCancer)
persona2
```

Aquí no se requiere convertir las variables del registro *persona2* a variables tipo categóricas tipo factor ya que son valores numéricos y el modelo así fue construido.

Se hace la predicción con estos valores:

Ahora con el modelo de clasificación 2 *knn*:

```{r}
predicciones.2 <- knn(train = datos.entrenamiento[muestra, -1], test = persona2[, -1], cl = datos.entrenamiento[muestra,1], k = 12)
predicciones.2

```

La predicción es que **LA PERSONA NO** se clasifica con daño al corazón con el modelo *knn.*

::: {probando="" style="color: red;"}
extraño es que un modelo dice **SI** y otro dice NO; los valores a probar son similares de la misma persona ... mmm ...
:::

¿que predicciones se generaron en los otros modelos?. Habiendo construido modelos de basados en los algoritmos de regresión logística binaria y árbol de regresión, en estos las predicciones fueron de que '*YES*' si tiene daño al corazón.

# Interpretación

Pendiente

# Bibliografía
