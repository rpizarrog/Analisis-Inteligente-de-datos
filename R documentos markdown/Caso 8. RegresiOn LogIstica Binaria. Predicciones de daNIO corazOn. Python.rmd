---
title: "Caso 8. Regresi√≥n Log√≠stica Binaria. Predicciones de da√±o coraz√≥n. Python"
author: "Rub√©n Pizarro Gurrola"
date: "`r Sys.Date()`"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
    toc_depth: 6
    number_sections: yes
bibliography: references.bib
---

# Objetivo

Implementar el modelo de regresi√≥n log√≠stica binaria con datos relacionados a una condici√≥n de salud de las personas para predecir anomal√≠as de coraz√≥n y evaluar la exactitud del modelo mediante la matriz de confusi√≥n.

# Descripci√≥n

Se cargan librer√≠as y se descargan los datos: <https://raw.githubusercontent.com/rpizarrog/Analisis-Inteligente-de-datos/main/datos/heart_2020_cleaned.csv>

Los datos est√°n relacionados con aspectos m√©dicos y son valores num√©ricos de varias variables que caracterizan el estado de salud de 319,795 personas.

Se pretende construir un modelo utilizando **algoritmos supervisados** para resolver la **tarea de clasificaci√≥n binaria** e identificar si una persona padece del coraz√≥n o no.

Se construyen datos de entrenamiento y validaci√≥n al 80% y 20% cada uno.

Se desarrollan los modelos de:

-   **Regresi√≥n Log√≠stica binaria**

-   √Årbol de Clasificaci√≥n tipo class

-   K Means

-   SVM Lineal

-   SVM Polinomial

-   SVM Radial

Los modelo se aceptan si tienen un valor de exactitud ("*Accuracy*") por encima del 70%..

El modelo se construye con funciones de librer√≠as de *python*

# Fundamento te√≥rico

La regresi√≥n log√≠stica ofrece soluci√≥n para clasificar y para predecir valores l√≥gicos, es decir con un valor etiquetado tal vez 0 o 1; bueno o malo, alto o bajo, entre otras etiquetas que distingan una polaridad o significado dicot√≥mico, o un valor u otro.

Para predicciones el modelo de regresi√≥n log√≠stica binaria encuentra la probabilidad de ocurrencia de un evento determinado y dicha probabilidad se hallar√° siempre dentro del rango.

Cuando la variable respuesta posee dos categor√≠as, entonces se estar√° delante de una regresi√≥n log√≠stica binaria.

En cambio, si la variable respuesta posee m√°s de dos categor√≠as, se usar√° la regresi√≥n log√≠stica multinomial .

El resultado real de muchos algoritmos de clasificaci√≥n binaria es una puntuaci√≥n de predicci√≥n en t√©rminos de probabilidad. La probabilidad indica la posible del modelo de que la observaci√≥n dada pertenezca a la clase positiva.

Para tomar la decisi√≥n sobre si la observaci√≥n debe clasificarse como positiva o negativa, como interpretaci√≥n de la probabilidad se define el umbral de clasificaci√≥n o el corte que normalmente es 50% arriba es positiva y 50% abajo es negativa y compara con la puntuaci√≥n con dicho umbral de la predicci√≥n.

Cualquier observaci√≥n con puntuaciones superiores al umbral se prev√© como la clase positiva y las puntuaciones inferiores al umbral se prev√©n como la clase negativa.[@amazonmahinelearning].

En este caso que se presenta y describe a continuaci√≥n, se utiliza la regresi√≥n log√≠stica binomial como parte de los algoritmos supervisados de machine learning.

El modelo requiere una cantidad de variables independientes del modelo $x_1, x_2 ... x_n$ √≥ $\beta_1, \beta_2...\beta_n$.

Se debe identificar la variable dependiente $Y$ o la variable respuesta de tipo binaria, donde cada componente de ùëå se distribuye mediante una distribuci√≥n de Bernoulli $[ 0 | 1]$.

Se necesitan $ùëõ$ el n√∫mero de observaciones.

Entonces $ùëã = (ùë•_1, ‚Ä¶ , ùë•_ùëõ)^T$ el conjunto de variable independientes.

Se identifica como $\theta$ el vector de par√°metros asociado al modelo, de forma que $\theta\in R^{k+1}$ que significa que los valores del vector resultante pertenecen a cada una de las variables.

Sea $\pi(\theta^Tùë•_ùëñ)$ la probabilidad de que $Y_i$ tome un valor igual a $1$, entonces su modelo se puede escribir como:

$$
\pi(\theta^Tx_i) = P(Y =1|X=x) = \frac{1}{1+e}
$$

Si $\theta^Tx_i$ los valores ajustados toma valores elevados y positivos, entonces ... ... se aproximar√° a 0 y, en consecuencia, el valor de la funci√≥n anterior ser√° igual a 1. En caso de que $\theta^Tx_i$ tome valores elevados pero negativos, entonces el valor de la funci√≥n ser√° $0$ dado que $e ^ {\theta^Tx_i}$ tender√° a infinito. [@zang2020].

El valor $e$ como n√∫mero irracional y basado en la teor√≠a de logaritmos naturales es el valor constante que se puede obtener en lenguaje R con la funci√≥n exp(1) igual a r exp(1).

Efectuando la transformaci√≥n logit a la expresi√≥n inicial, se obtiene:

$$
logit(\pi(\theta^Tx_i)) = ln(\frac{\pi(\theta^Tx_i)}{1 - \pi(\theta^Tx_i)})
$$

que significa calcular el logaritmo natural de cada valor de de $x_i$ para determinar su probabilidad.

# Desarrollo

## Cargar librer√≠as

Librer√≠a nueva que hay que nstalar:

-   py_install("plotnine") \# desde R es para gr√°ficos *ggplot en caso de usarse*

-   *py_install("sidetable")* para tablas de frecuencias se usa en gr√°ficos de barras

```{python}
# Tratamiento de datos
import pandas as pd
import numpy as np

# Estad√≠sticas
import scipy
from scipy import stats

# Para partir datos entrenamiento y validaci√≥n
from sklearn.model_selection import train_test_split

# Modelo de Clasificaci√≥n 
from sklearn import linear_model
from sklearn import model_selection
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

# Gr√°ficos
import matplotlib.pyplot as plt
import seaborn as sb

# Graficos ggplot similar a R
from plotnine import *  # Antes instalar > py_install("plotnine") desde R o Python

# tablas de frecuencias
import sidetable as stb

```

## Cargar datos

Se cargan datos del enlace *URL*, se observan los primeros y √∫ltimos registros del conjunto de datos.

```{python}
datos = pd.read_csv("https://raw.githubusercontent.com/rpizarrog/Analisis-Inteligente-de-datos/main/datos/heart_2020_cleaned.csv")
datos
```

## Exploraci√≥n de datos

Son 319795 observaciones y 18 variables

```{python}
print("Observaciones y variables: ", datos.shape)
print("Columnas y tipo de dato")
# datos.columns
datos.dtypes
```

### Visualizaci√≥n de datos

#### ¬øCu√°ntos casos hay de cada clase?

Hay 292422 casos sin da√±o al coraz√≥n y el resto que si tienen da√±o 27373.

```{python}
frecuencia = (datos.groupby("HeartDisease").agg(frecuencia=("HeartDisease","count")).reset_index())
  
frecuencia
```

```{python}


fig, ax = plt.subplots()
# Colores
bar_labels = ['No', 'Yes']
bar_colors = ['tab:blue', 'tab:red']

#frecuencia['frecuencia'].plot(kind="bar")
ax.bar(frecuencia['HeartDisease'], frecuencia['frecuencia'], label=bar_labels, color=bar_colors)

ax.set_ylabel('Frecuencia')
ax.set_title('Da√±os al Coraz√≥n')
ax.legend(title='Da√±o')

plt.show()
# plt.gcf().clear()

```

#### Histogramas de datos num√©ricos

Histograma √∫nicamente de las variables num√©ricas del conjunto de datos *'BMI', 'PhysicalHealth', 'MentalHealth', 'SleepTime'.*

```{python}
datos[['BMI', 'PhysicalHealth', 'MentalHealth', 'SleepTime']].hist()

```

#### Diagramas de frecuencias de datos categ√≥ricos

Diagramas de frecuencias con barras de las variables categ√≥ricas: 'Smoking', 'AlcoholDrinking', 'Stroke', ...,.

```{python}
frecuencia = (datos.groupby("Smoking").agg(frecuencia=("Smoking", "count")).reset_index())

fig, ax = plt.subplots()
# Colores
bar_labels = ['No', 'Yes']
bar_colors = ['tab:blue', 'tab:red']

#frecuencia['frecuencia'].plot(kind="bar")
ax.bar(frecuencia['Smoking'], frecuencia['frecuencia'], label=bar_labels, color=bar_colors)

ax.set_ylabel('Frecuencia')
ax.set_title('Fumador')
ax.legend(title='Da√±o')

# plt.show()
# plt.gcf().clear()
  
  

```

## Transformar datos

Crear variable llamada *HeartDisease01* que se utilizar√° en el modelo de **Regresi√≥n Log√≠stica** tendr√° valores **0** de para 'No' da√±o y **1** para si hay da√±o ('*Yes*').

```{python}
datos['HeartDisease01'] = np.where(datos ['HeartDisease']== "Yes", 1, 0)
 
```

Quitar la variable HeartDisease que ya tiene variable transformada a HeartDisease01

```{python}
datos = datos.drop("HeartDisease", axis='columns')
```

Quedaron las columnas:

```{python}
datos.columns.values
```

### Las variables de inter√©s

Todas las variables de entrada o variables independientes:

-   "*BMI*": Indice de masa corporal con valores entre 12.02 y 94.85.

-   "*Smoking*": Si la persona es fumadora o no con valores categ√≥ritos de 'Yes' o 'No'.

-   "*AlcoholDrinking*" : Si consume alcohol o no, con valores categ√≥ricos de 'Yes' o 'No'.

-   "*Stroke*": Si padece alguna anomal√≠a cerebrovascular, apoplejia o algo similar, con valores categ√≥ricos de 'Yes' o 'No'.

-   "*PhysicalHealth*" Estado f√≠sico en lo general con valores entre 0 y 30.

-   "*MentalHealth*". Estado mental en lo general con valores entre 0 y 30.

-   "*DiffWalking*" . Que si se le dificulta caminar o tiene alg√∫n padecimiento al caminar, con valores categ√≥ritoc de 'Yes' o 'No'.

-   "*Sex*": G√©nero de la persona, con valores de 'Female' y 'Male' para distinguir al g√©nero femenino y masculino respectivamente.

-   "*AgeCategory*": Una clasificaci√≥n de la edad de la persona de entre 18 y 80 a√±os. La primera categor√≠a con un rango de edad entre 18-24, a partir de 25 con rangos de 5 en 5 hasta la clase de 75-80 y una √∫ltima categor√≠a mayores de 80 a√±os.

-   "*Race*". Raza u origen de la persona con valores categ√≥ricos de '*American Indian/Alaskan Native', 'Asian','Black', 'Hispanic', 'Other'* y'*White'.*

-   "*Diabetic*". Si padece o ha padecido de diabetes en cuatro condiciones siendo Yes y No para si o no: 'No', 'borderline diabetes' condici√≥n antes de detectarse diabetes tipo 2, 'Yes', y 'Yes (during pregnancy)' durante embarazo.

-   "*PhysicalActivity*" que si realiza actividad f√≠sica, con valores categ√≥ricos de 'Yes' o 'No'.

-   "*GenHealth*": EStado general de salud de la persona con valores categ√≥ricos de 'Excellent', 'Very good', 'Good', 'Fair' y 'Poor' con significado en espa√±ol de excelente, muy buena, buena, regular y pobre o deficiente.

-   "*SleepTime*": valor num√©rico de las horas de sue√±o u horas que duerme la persona con valores en un rango entre 1 y 24.

-   "*Asthma*": si padece de asma o no, con valores categ√≥ricos de 'Yes' o 'No'.

-   "*KidneyDisease*": si tiene alg√∫n padecimiento en los ri√±ones, con valores categ√≥ricos de 'Yes' o 'No'.

-   "*SkinCancer*": si padece alg√∫n tipo de c√°ncer de piel, con valores categ√≥ricos de 'Yes' o 'No'.

La variable de inter√©s como dependiente o variable de salida es la de da√±o al coraz√≥n (*HeartDisease*), con valores categ√≥ricos de 'Yes' o 'No' , ahora la variable *HeartDisease01* con valores *'1' o '0'.*

Nuevamente la descripci√≥n de variables y ahora son 319795 observaciones y 18 variables

```{python}
print("Observaciones y variables: ", datos.shape)
print("Columnas y tipo de dato")
# datos.columns
datos.dtypes
```

### Construir variables Dummys

Existen variables que son categ√≥ricas: *'Smoking', 'AlcoholDrinking', 'Stroke', 'DiffWalking', 'Sex', 'AgeCategory', 'Race', 'Diabetic', 'PhysicalActivity', 'GenHealth', 'Asthma', 'KidneyDisease', 'SkinCancer'*.

Con estas variables, crear variables *Dummys* y construir un conjunto de datos que incluye las variable dummis.

El m√©todo de la librer√≠a de Pandas llamado *get_dummies()* convierte los datos categ√≥ricos en variables indicadoras o ficticias.

```{python}
datos_dummis = pd.get_dummies(datos, drop_first = True)
datos_dummis
```

Asi queda el conjunto de datos preparado llamado *datos_dummis*

```{python}
datos_dummis.dtypes
```

## Datos de entrenamiento y validaci√≥n

Datos de entrenamiento al 80% de los datos y 20% los datos de validaci√≥n. Semilla 2022

```{python}
X_entrena, X_valida, Y_entrena, Y_valida = train_test_split(datos_dummis.drop(columns = "HeartDisease01"), datos_dummis['HeartDisease01'],train_size = 0.80,  random_state = 2022)
```

### Datos de entrenamiento

```{python}
X_entrena
```

### Datos de validaci√≥n

```{python}
X_valida
```

## Modelos Supervisados de Clasificaci√≥n

Se construye un modelo de regresi√≥n log√≠stica con los datos de entrenamiento y las variables independientes.

```{python}
modelo_rlog = linear_model.LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
intercept_scaling=1, max_iter=1000)
modelo_rlog.fit(X_entrena, Y_entrena)
```

```{python}
print(modelo_rlog.score(X_entrena, Y_entrena))
```

### Predicciones

Se hacen predicciones con los datos de validaci√≥n. Se observan las primeras 10.

```{python}
predicciones_rlog = modelo_rlog.predict(X_valida)
print(predicciones_rlog[0:10])
```

### Tabla comparativa

```{python}
comparaciones = pd.DataFrame(X_valida)
comparaciones = comparaciones.assign(HeartDisease_Real = Y_valida)
comparaciones = comparaciones.assign(HeartDisease_Pred = predicciones_rlog.flatten().tolist())
print(comparaciones)

```

### Evaluaci√≥n del modelo

Se eval√∫a el modelo con la matriz de confusi√≥n

#### Matriz de confusi√≥n

```{python}
print(confusion_matrix(comparaciones['HeartDisease_Real'], comparaciones['HeartDisease_Pred']))


```

#### ¬øA cuantos le atina el modelo?

```{python}
print(classification_report(comparaciones['HeartDisease_Real'], comparaciones['HeartDisease_Pred']))


```

### Predicciones con datos nuevos

Se crea un registro de una persona con ciertas condiciones de salud.

```{r}
BMI = 38
Smoking = 1 #'Yes'
AlcoholDrinking = 1 #'Yes'
Stroke = 1 #'Yes'
# PhysicalHealth = 2
# MentalHealth = 5
DiffWalking = 1 #'Yes'
# Sex = 'Male'
# AgeCategory = '70-74'
# Race = 'Black'
# Diabetic <- 'Yes'
# PhysicalActivity = "No"
# GenHealth = "Fair"
# SleepTime = 12
# Asthma = "Yes"
# KidneyDisease = "Yes"
# SkinCancer = 'No'
# persona = data.frame(BMI,Smoking, AlcoholDrinking, Stroke, PhysicalHealth, MentalHealth, DiffWalking, Sex, AgeCategory, Race, Diabetic, PhysicalActivity, GenHealth, SleepTime, Asthma, KidneyDisease, SkinCancer)
#persona
```

Se hace la predicci√≥n con estos valores de si tiene p no da√±o en el coraz√≥n:

### Interpretaci√≥n

Se hace una evaluaci√≥n del modelo de regresi√≥n log√≠stica basada en el estad√≠stico de *accuracy* de la matriz de confusi√≥n.

Hhabiendo realizado predicciones con los datos de validaci√≥n, se tiene un valor de aproximadamente del $92%$ con el de exactitud en el modelo de regresion log√≠stica .

El modelo se aprueba dado que la m√©trica era igual o superior del $70%$.

¬°El modelo es bueno!

# Bibliograf√≠a
